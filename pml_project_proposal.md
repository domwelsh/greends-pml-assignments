# **Climate Simulation Model**
**Category:** Tabular Data  
**Name:** Dominic Welsh  
**Student ID:** 127909  

## **Description**
[Kaggle Project Link](https://www.kaggle.com/competitions/leap-atmospheric-physics-ai-climsim/overview)

### **Overview**
Climate models are used to better understand Earth's systems, both current systems and to predict future systems. Most climate models have grid sizes of 50-100 km, and for processes that occur at smaller scales than this the models approximate what happens, but these approximations are not good. There is a Multi-scale Modeling Framework (MMF) approach to calculate these subgrid processes, but it's very computationally intensive.

### **Problem Statement**
I will be creating a ML model, trained on MMF data, that will be able to produce results similar to the MMF approach, but will take a lot less processing power to produce results and therefore be more useable in a variety of scenarios. I find this problem very interesting because I get to try and create a model that improves a process that is already being used a lot, and it will be my first project of combining environmental data with machine learning.

### **Challenges**
1. A much larger dataset than I've worked with before. The training dataset provided on Kaggle is 181 GBs, and an even larger dataset can be used from the competition's GitHub. So far, all the models I've worked on it's been pretty quick to make adjustments, see how they do, and then repeat. But when it will take several hours to run my model on the entire training dataset, I won't be able to do that.
2. A lot of input and output variables. There are 25 input variables, but because a lot of these variables have values in each of the 60 vertical levels recorded (such as air temperature), there's a total of 556 input variables. And similarly, there are 14 target variables, but again about half of them need a value for each of the 60 vertical levels, so there's 368 values that need to be outputted for each 556 input.
3. I have not worked this in depth on climate before, so I don't know what a lot of the data is about or how the different data might correlate or not with each other.

### **Dataset**
The dataset is provided on the Kaggle challenge page, and it was generated by the E3SM-MMF climate model. The dataset can be acquired through Kaggle by signing up to the competition, or through [LEAP's Hugging Face page](https://huggingface.co/LEAP), which also has the full 41.2 TB high resolution dataset.

### **Method or Algorithm**
Due to the complexity of the dataset and outputs, I will probably start with a type of neural network. There are papers about using CNN for climate data, because even though it is tabular data, each of the input data points do relate to each other and therefore could be effectively grouped into a kernel. But I would need to do more research before trying that out.  

### **Evaluation**
The challenge uses an R-squared metric for evaluating submitted models, which is:
$$ R^2 = 1 - {SSres \over SStot}$$
SSres = sum of squares of the residual errors  
SStot = total sum of squares

I will be evaluating my model the same way
